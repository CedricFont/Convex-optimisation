{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "from cvxpy.atoms.affine.wraps import psd_wrap\n",
    "from read_data import *\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%       MGT - 418         %%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%      Convex Optimization - Project 2          %%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%             2021-2022 Fall                    %%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%      Learning the Kernel Function             %%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_fit(kernel, y_tr, rho):\n",
    "    \"\"\"\n",
    "    Dual of soft-margin SVM problem (2)\n",
    "    Use cvxpy.atoms.affine.psd_wrap for each G(\\hat K^l) matrix when it appear in the constraints and in the objective\n",
    "    \"\"\"\n",
    "    n_tr = len(y_tr)\n",
    "    G =  kernel*y_tr[:,np.newaxis]*y_tr[:,np.newaxis].T\n",
    "    lambda_ = cp.Variable(n_tr)\n",
    "    dual_obj = cp.Maximize(cp.sum(lambda_) - 1/(2*rho)*cp.quad_form(lambda_, psd_wrap(G)))\n",
    "    cons = []\n",
    "    cons.append(lambda_@y_tr == 0)\n",
    "    cons.append(lambda_ >= 0)\n",
    "    cons.append(lambda_ <= 1)\n",
    "    prob = cp.Problem(dual_obj, cons)\n",
    "    prob.solve(solver=cp.MOSEK)\n",
    "    lambda_opt = lambda_.value\n",
    "    b_opt =  cons[0].dual_value\n",
    "    return lambda_opt, b_opt\n",
    "\n",
    "\n",
    "def svm_predict(kernel, y_tr, y_te, lambda_opt, b_opt, rho):\n",
    "    \"\"\"\n",
    "    Predict function for kernel SVM. \n",
    "    See lecture slide 183.\n",
    "    \"\"\"\n",
    "    n_te = len(y_te)\n",
    "    n_tr = len(y_tr)\n",
    "    testing_acc = 0\n",
    "    \n",
    "    for i in range(n_te):\n",
    "        if(y_te[i] == np.sign(1/rho*(lambda_opt*y_tr*kernel[n_tr + i,:n_tr]).sum() + b_opt)): testing_acc += 1\n",
    "    \n",
    "    acc = testing_acc/n_te\n",
    "    return acc\n",
    "\n",
    "def kernel_learning(K1, K2, K3, y_tr, rho):\n",
    "    \"\"\"\n",
    "    Kernel learning for soft margin SVM. \n",
    "    Implementation of problem (5)\n",
    "    Use cvxpy.atoms.affine.psd_wrap for each G(\\hat K^l) matrix when it appear in the constraints and in the objective\n",
    "    \"\"\"\n",
    "    # Traces\n",
    "    r1 = np.trace(K1) \n",
    "    r2 = np.trace(K2)\n",
    "    r3 = np.trace(K3)\n",
    "    G1 = np.multiply(np.multiply(K1,y_tr[:,np.newaxis]),y_tr)\n",
    "    G2 = np.multiply(np.multiply(K2,y_tr[:,np.newaxis]),y_tr)\n",
    "    G3 = np.multiply(np.multiply(K3,y_tr[:,np.newaxis]),y_tr)\n",
    "    # Variables\n",
    "    n_tr = len(y_tr)\n",
    "    lambda_ = cp.Variable(n_tr)\n",
    "    z = cp.Variable(1)\n",
    "    c = r1 + r2 + r3\n",
    "    \n",
    "    cons = []\n",
    "    cons.append(z * r1 >= 1/ (2 * rho) * cp.quad_form(lambda_, psd_wrap(G1)))\n",
    "    cons.append(z * r2 >= 1/ (2 * rho) * cp.quad_form(lambda_, psd_wrap(G2)))\n",
    "    cons.append(z * r3 >= 1/ (2 * rho) * cp.quad_form(lambda_, psd_wrap(G3)))\n",
    "    cons.append(lambda_.T@y_tr == 0)\n",
    "    cons.append(lambda_ >= 0)\n",
    "    cons.append(lambda_ <= 1)\n",
    "    \n",
    "    obj = cp.Maximize(lambda_.T@np.ones(n_tr) - c*z)\n",
    "    \n",
    "    prob = cp.Problem(obj, cons)\n",
    "    prob.solve(solver=cp.MOSEK)\n",
    "\n",
    "    mu_opt1 = cons[0].dual_value\n",
    "    mu_opt2 = cons[1].dual_value\n",
    "    mu_opt3 = cons[2].dual_value\n",
    "    \n",
    "    b_opt = cons[3].dual_value\n",
    "    \n",
    "    return mu_opt1, mu_opt2, mu_opt3, lambda_.value, b_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. a) & b) Preprocess data and solve QCQP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "acc_opt_kernel = []    \n",
    "acc_poly_kernel = []    \n",
    "acc_gauss_kernel = []    \n",
    "acc_linear_kernel = []    \n",
    "rho = 2\n",
    "data, labels = prepare_ionosphere_dataset()\n",
    "data = data.astype(float)\n",
    "#############################################\n",
    "k1 = lambda x, xp, p: (1 + x.T@xp)**p\n",
    "k2 = lambda x, xp, sigma: np.exp((-(x - xp).T@(x - xp)/(2*sigma)))\n",
    "k3 = lambda x, xp: x.T@xp\n",
    "#############################################\n",
    "msk = np.int_(np.random.choice(data.shape[0], size=data.shape[0], replace=False)) \n",
    "\n",
    "test_to_train_ratio = .2\n",
    "n_tr = np.int(data.shape[0]*(1 - test_to_train_ratio))\n",
    "\n",
    "x_tr = data[msk[0:n_tr],:]\n",
    "x_te = data[msk[n_tr:],:]\n",
    "y_tr = labels[msk[0:n_tr]]\n",
    "y_te = labels[msk[n_tr:]]\n",
    "\n",
    "n_tr = y_tr.shape[0]\n",
    "n_te = y_te.shape[0]\n",
    "n_tr = x_tr.shape[0]\n",
    "n_te = x_te.shape[0]\n",
    "\n",
    "x_all = np.vstack([x_tr, x_te])\n",
    "n_all = x_all.shape[0]\n",
    "\n",
    "K1 = k1(x_all.T,x_all.T,p=2)\n",
    "K2 = k2(x_all.T,x_all.T,sigma=.5)\n",
    "K3 = k3(x_all.T,x_all.T)\n",
    "\n",
    "mu_opt1, mu_opt2, mu_opt3, lambda_opt, b_opt = kernel_learning(K1[:n_tr,:n_tr], K2[:n_tr,:n_tr], K3[:n_tr,:n_tr], y_tr, rho)\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. c) SVM predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9014084507042254"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_kernel = mu_opt1*K1 + mu_opt2*K2 + mu_opt3*K3\n",
    "\n",
    "svm_predict(opt_kernel, y_tr, y_te, lambda_opt, b_opt, rho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. & 6. : cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration-->0\n",
      "Iteration-->1\n",
      "Iteration-->2\n",
      "Iteration-->3\n",
      "Iteration-->4\n",
      "Iteration-->5\n",
      "Iteration-->6\n",
      "Iteration-->7\n",
      "Iteration-->8\n",
      "Iteration-->9\n",
      "Iteration-->10\n",
      "Iteration-->11\n",
      "Iteration-->12\n",
      "Iteration-->13\n",
      "Iteration-->14\n",
      "Iteration-->15\n",
      "Iteration-->16\n",
      "Iteration-->17\n",
      "Iteration-->18\n",
      "Iteration-->19\n",
      "Iteration-->20\n",
      "Iteration-->21\n",
      "Iteration-->22\n",
      "Iteration-->23\n",
      "Iteration-->24\n",
      "Iteration-->25\n",
      "Iteration-->26\n",
      "Iteration-->27\n",
      "Iteration-->28\n",
      "Iteration-->29\n",
      "Iteration-->30\n",
      "Iteration-->31\n",
      "Iteration-->32\n",
      "Iteration-->33\n",
      "Iteration-->34\n",
      "Iteration-->35\n",
      "Iteration-->36\n",
      "Iteration-->37\n",
      "Iteration-->38\n",
      "Iteration-->39\n",
      "Iteration-->40\n",
      "Iteration-->41\n",
      "Iteration-->42\n",
      "Iteration-->43\n",
      "Iteration-->44\n",
      "Iteration-->45\n",
      "Iteration-->46\n",
      "Iteration-->47\n",
      "Iteration-->48\n",
      "Iteration-->49\n",
      "Iteration-->50\n",
      "Iteration-->51\n",
      "Iteration-->52\n",
      "Iteration-->53\n",
      "Iteration-->54\n",
      "Iteration-->55\n",
      "Iteration-->56\n",
      "Iteration-->57\n",
      "Iteration-->58\n",
      "Iteration-->59\n",
      "Iteration-->60\n",
      "Iteration-->61\n",
      "Iteration-->62\n",
      "Iteration-->63\n",
      "Iteration-->64\n",
      "Iteration-->65\n",
      "Iteration-->66\n",
      "Iteration-->67\n",
      "Iteration-->68\n",
      "Iteration-->69\n",
      "Iteration-->70\n",
      "Iteration-->71\n",
      "Iteration-->72\n",
      "Iteration-->73\n",
      "Iteration-->74\n",
      "Iteration-->75\n",
      "Iteration-->76\n",
      "Iteration-->77\n",
      "Iteration-->78\n",
      "Iteration-->79\n",
      "Iteration-->80\n",
      "Iteration-->81\n",
      "Iteration-->82\n",
      "Iteration-->83\n",
      "Iteration-->84\n",
      "Iteration-->85\n",
      "Iteration-->86\n",
      "Iteration-->87\n",
      "Iteration-->88\n",
      "Iteration-->89\n",
      "Iteration-->90\n",
      "Iteration-->91\n",
      "Iteration-->92\n",
      "Iteration-->93\n",
      "Iteration-->94\n",
      "Iteration-->95\n",
      "Iteration-->96\n",
      "Iteration-->97\n",
      "Iteration-->98\n",
      "Iteration-->99\n",
      "Average dual accuracy with optimal kernel is 0.9052112676056336\n",
      "Average dual accuracy with polynomial kernel is 0.9087323943661971\n",
      "Average dual accuracy with gaussian kernel is 0.6383098591549294\n",
      "Average dual accuracy with linear kernel is 0.8638028169014084\n"
     ]
    }
   ],
   "source": [
    "for iters in range(100): \n",
    "    ## Please do not change the random seed.\n",
    "    np.random.seed(iters)\n",
    "    ### Training-test split\n",
    "    msk = np.int_(np.random.choice(data.shape[0], size=data.shape[0], replace=False)) \n",
    "    \n",
    "    x_tr = data[msk[0:n_tr],:]\n",
    "    x_te = data[msk[n_tr:],:]\n",
    "    y_tr = labels[msk[0:n_tr]]\n",
    "    y_te = labels[msk[n_tr:]]\n",
    " \n",
    "    n_tr = y_tr.shape[0]\n",
    "    n_te = y_te.shape[0]\n",
    "    n_tr = x_tr.shape[0]\n",
    "    n_te = x_te.shape[0]\n",
    "    \n",
    "    x_all = np.vstack([x_tr, x_te])\n",
    "    n_all = x_all.shape[0]\n",
    "\n",
    "    ## Prepare the initial choice of kernels \n",
    "    # It is recommended to prepare the kernels for all the training and the test data\n",
    "    # Then, the kernel size will be (n_tr + n_te)x(n_tr + n_te).\n",
    "    # Use only the training block (like K1[0:n_tr, 0:n_tr] ) to learn the classifier \n",
    "    # (for the functions svm_fit and kernel_learning).\n",
    "    # When predicting you may use the whole kernel as it is. \n",
    "    K1 = k1(x_all.T,x_all.T,p=2)\n",
    "    K2 = k2(x_all.T,x_all.T,sigma=.5)\n",
    "    K3 = k3(x_all.T,x_all.T)\n",
    "\n",
    "    mu_opt1, mu_opt2, mu_opt3, lambda_opt, b_opt = kernel_learning(K1[:n_tr,:n_tr], K2[:n_tr,:n_tr], K3[:n_tr,:n_tr], y_tr, rho)\n",
    "    opt_kernel = mu_opt1*K1 + mu_opt2*K2 + mu_opt3*K3\n",
    "    acc_opt_kernel.append(svm_predict(opt_kernel, y_tr, y_te, lambda_opt, b_opt, rho))\n",
    "    \n",
    "    lambda_opt, b_opt = svm_fit(K1[:n_tr,:n_tr], y_tr, rho)\n",
    "    acc_poly_kernel.append(svm_predict(K1, y_tr, y_te, lambda_opt, b_opt, rho))\n",
    "    \n",
    "    lambda_opt, b_opt = svm_fit(K2[:n_tr,:n_tr], y_tr, rho)\n",
    "    acc_gauss_kernel.append(svm_predict(K2, y_tr, y_te, lambda_opt, b_opt, rho))\n",
    "    \n",
    "    lambda_opt, b_opt = svm_fit(K3[:n_tr,:n_tr], y_tr, rho)\n",
    "    acc_linear_kernel.append(svm_predict(K3, y_tr, y_te, lambda_opt, b_opt, rho))\n",
    "    print('Iteration-->' + str(iters))\n",
    "print('Average dual accuracy with optimal kernel is ' + str(np.mean(acc_opt_kernel)))\n",
    "print('Average dual accuracy with polynomial kernel is ' + str(np.mean(acc_poly_kernel)))\n",
    "print('Average dual accuracy with gaussian kernel is ' + str(np.mean(acc_gauss_kernel)))\n",
    "print('Average dual accuracy with linear kernel is ' + str(np.mean(acc_linear_kernel)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
